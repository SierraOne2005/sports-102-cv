{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13048941,"sourceType":"datasetVersion","datasetId":8263090}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import models, datasets, transforms\nfrom torch.cuda.amp import autocast, GradScaler\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom torch import amp\nimport numpy as np\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Seeding for Reproducibility\n# =============================\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Set your desired seed\nSEED = 42\nseed_everything(SEED)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Configuration\n# =============================\ndata_dir = \"/kaggle/input/sports-102/Sports102_V2\"\noutput_dir = \"/kaggle/working/vitb16_sports102_outputs\"\nos.makedirs(output_dir, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nbatch_size = 32\nnum_epochs = 50\nlearning_rate = 2e-4\nlog_interval = 10  # Log loss every 10 mini-batches\nimg_size = 224","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Data Loading and Transforms\n# =============================\ntrain_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((img_size, img_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]),\n])\n\n# This split is now reproducible thanks to torch.manual_seed()\nfull_train_dataset = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform)\ntrain_size = int(0.8 * len(full_train_dataset))\nval_size = len(full_train_dataset) - train_size\ntrain_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\ntest_dataset = datasets.ImageFolder(os.path.join(data_dir, \"test\"), transform=test_transform)\n\n# --- CHANGES FOR DATALOADER ---\ndef seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(SEED) # Use the same seed as before\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4,\n    worker_init_fn=seed_worker,\n    generator=g\n)\n# -----------------------------\n\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\nnum_classes = len(full_train_dataset.classes)\nprint(f\"Number of classes: {num_classes}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Model Setup\n# =============================\n# 1. Load the pretrained ViT model with its original weights\nmodel = models.vit_b_16(weights=models.ViT_B_16_Weights.IMAGENET1K_V1)\n\n# 2. Replace the final classification layer (the \"head\")\n# The original ViT head classifies 1000 classes (ImageNet). \n# We replace it with a new linear layer for our 102 classes.\nnum_features = model.heads.head.in_features\nmodel.heads.head = nn.Linear(num_features, num_classes)\n\n# 3. Move the model to the GPU\nmodel = model.to(device)\n\n# --- The rest of the setup remains the same ---\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)\nscaler = torch.amp.GradScaler()\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", patience=4, factor=0.5)\nprint(f\"Initial learning rate: {scheduler.get_last_lr()}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Resume Checkpoint\n# =============================\nstart_epoch = 0\nbest_val_acc = 0.0\ncheckpoint_path = os.path.join(output_dir, \"checkpoint.pth\")\nbest_model_path = os.path.join(output_dir, \"best_model.pth\")\n\nif os.path.exists(checkpoint_path):\n    print(\"Resuming from checkpoint...\")\n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n    scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n    best_val_acc = checkpoint[\"best_val_acc\"]\n    start_epoch = checkpoint[\"epoch\"] + 1\n    print(f\"Resumed from epoch {start_epoch} with best val acc {best_val_acc:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Training Loop\n# =============================\ntrain_losses = []\nval_losses = []\nbest_val_acc = 0.0\n\nfor epoch in range(start_epoch, num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct, total = 0, 0\n    global_step = epoch * len(train_loader)\n\n    for i, (images, labels) in enumerate(tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")):\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        with amp.autocast(device_type=\"cuda\"):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n\n    train_acc = 100 * correct / total\n    train_loss = running_loss / len(train_loader)\n    train_losses.append(train_loss)\n\n    # Validation\n    model.eval()\n    val_loss, val_correct, val_total = 0, 0, 0\n    with torch.no_grad(), amp.autocast(device_type=\"cuda\"):\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = outputs.max(1)\n            val_total += labels.size(0)\n            val_correct += predicted.eq(labels).sum().item()\n\n    val_acc = 100 * val_correct / val_total\n    val_loss /= len(val_loader)\n    val_losses.append(val_loss)\n\n    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n          f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n          f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n\n\n    scheduler.step(val_acc)\n\n    # Checkpointing (every epoch)\n    torch.save({\n        \"epoch\": epoch,\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n        \"scheduler_state_dict\": scheduler.state_dict(),\n        \"best_val_acc\": best_val_acc,\n    }, checkpoint_path)\n\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(model.state_dict(), best_model_path)\n        print(\"âœ… Saved best model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# =============================\n# Evaluation (Train, Val, Test)\n# =============================\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndef evaluate(loader, name):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad(), torch.amp.autocast(\"cuda\"):\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = outputs.max(1)\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    report = classification_report(all_labels, all_preds, output_dict=True, target_names=full_train_dataset.classes)\n    print(f\"\\n{name} Classification Report:\")\n    print(classification_report(all_labels, all_preds, target_names=full_train_dataset.classes))\n    acc = report[\"accuracy\"] * 100\n    return report, all_labels, all_preds\n\ndef plot_confusion_matrix(y_true, y_pred, class_names, normalize=False, figsize=(30, 30), fontsize=6, save_path=None):\n    cm = confusion_matrix(y_true, y_pred)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    plt.figure(figsize=figsize)\n    sns.heatmap(cm, annot=True, fmt=\".2f\" if normalize else \"d\", cmap=\"Blues\",\n                xticklabels=class_names, yticklabels=class_names, cbar=True)\n\n    plt.ylabel('True label', fontsize=fontsize + 2)\n    plt.xlabel('Predicted label', fontsize=fontsize + 2)\n    plt.title('Confusion Matrix', fontsize=fontsize + 4)\n    plt.xticks(rotation=90, fontsize=fontsize)\n    plt.yticks(rotation=0, fontsize=fontsize)\n    plt.tight_layout()\n\n    if save_path:\n        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n        print(f\"âœ… Confusion matrix saved to: {save_path}\")\n\n    plt.show()\n\nprint(\"\\nLoading best model for final evaluation...\")\nmodel.load_state_dict(torch.load(best_model_path))\n\ntrain_report, _, _ = evaluate(train_loader, \"Train\")\nval_report, _, _ = evaluate(val_loader, \"Val\")\ntest_report, y_true, y_pred = evaluate(test_loader, \"Test\")\n\n# Print all accuracies together\nprint(\"\\nðŸ“Š Final Accuracies:\")\nprint(f\"Train Accuracy: {train_report['accuracy']*100:.2f}%\")\nprint(f\"Validation Accuracy: {val_report['accuracy']*100:.2f}%\")\nprint(f\"âœ… Test Accuracy: {test_report['accuracy']*100:.2f}%\")\n\n# Confusion Matrix for Test Set\nsave_path = os.path.join(output_dir, \"confusion_matrix.png\")\n\nprint(\"\\nðŸ”¹ Generating and saving confusion matrix for test set...\")\nplot_confusion_matrix(\n    y_true=y_true,\n    y_pred=y_pred,\n    class_names=full_train_dataset.classes,\n    normalize=False,  # Change to True if normalized matrix desired\n    figsize=(30, 30),\n    fontsize=6,\n    save_path=save_path\n)\n\nprint(\"âœ… Training complete. Confusion matrix saved.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}